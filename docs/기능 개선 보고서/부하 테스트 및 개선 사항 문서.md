### 부하 테스트의 필요성

통합 테스트를 많이 작성하고 진행하면서 “비즈니스 로직이 정상 동작한다.”는 검증 했지만 “얼마나 많은 트래픽을 감당할 수 있는지.”, “병목 지점은 어디인지” 를 검증하지는 못했다.

그래서 K6를 도입해 부하테스트를 진행해 성능 한계치를 테스트하고 DB connection pool 고갈, Redis 락 대기, Kafka consumer 등의 병목 지점을 탐색하고 개선하려고 한다.

### 모니터링 구축 과정

[Kafka 클러스터 구성, 모니터링 구축](https://www.notion.so/Kafka-25b13a3e1bfc80afbacff02141883c29?pvs=21)

위 작업에서는 prometheus, grafana 의 기본적인 구성만 구축했었다.
이어서 docker-compose.yml 에 추가로 mysql Exporter 설정과 .my.cnf를 추가한다.

```yaml
# docker-compose.yml
 mysqld-exporter:
    image: prom/mysqld-exporter
    command:
      - "--config.my-cnf=/etc/mysql/.my.cnf"
    volumes:
      - ./infra/mysql/.my.cnf:/etc/mysql/.my.cnf:ro
    ports:
      - "9104:9104"
    networks:
      - infra-net
    depends_on:
      - mysql
    restart: always
    
# .my.cnf
[client]
user=exporter
password=exporter_password
host=mysql
port=3306
```

그리고 datasource와 dashboard를 추가,
monitor의 compose.yml에서 grafana 볼륨 설정을 추가,
하드웨어 자원에 대한 데이터를 받기 위한 node exporter 설정 추가했다.

또한 경로 설정에 문제가 있던 것도 수정했다.

https://github.com/sky96027/e-commerce/commit/4f0b3683db550d00f6f5a4796928197e6a1e66b4

이후 kafka dashboard 를 찾아 추가했다.

https://github.com/sky96027/e-commerce/commit/46ec0babb676ba50216acc19b30cc6c116484e10

### 모니터링 화면

kafka dashboard

![카프카 대시보드.PNG](../images/부하%20테스트%20문서%20이미지/1.png)

node dashboard

![node 대시보드.PNG](../images/부하%20테스트%20문서%20이미지/2.png)

### 부하 테스트 선정

**부하 테스트 대상 : 선착순 쿠폰 발급 API (**`/coupon/issue`)

- 특징
    - 가상의 이벤트/프로모션 시 트래픽이 **단시간에 폭증**
    - 동시성 제어가 핵심
    - 성공/실패 응답 비율이 명확히 나타남

### 테스트 시나리오

1. 기본 동작 확인
    1. 옵션 : VU 50명, 30초 지속
    2. 목적 : k6 테스트 스크립트 확인, 모니터링 확인
2. 점진적 증가
    1. 옵션
        1. 1분 마다 500명 → 1000명 → 2000명으로 증가, 이후 점진적 감소
        2. 응답 시간 95% < 2초, 실패율 5%
    2. 목적
        1. 안정적으로 처리 가능한 최대 동시 사용자 수 확인
        2. 성능 임계치 도출
        3. 프로모션 시작 후 트래픽 폭증 상황 대응 능력 확인

### 테스트 스크립트 작성

```json
import http from 'k6/http';
import { check, sleep } from 'k6';

// 동작 확인
/*export const options = {
    vus: 50,
    duration: '30s',
    thresholds: {
        http_req_duration: ['p(95)<500'],
        http_req_failed: ['rate<0.01'],
    },
};*/

// 점진적 증가 (Ramp-up Stress Test)
export const options = {
    stages: [
        { duration: '1m', target: 500 },
        { duration: '1m', target: 1000 },
        { duration: '1m', target: 2000 },
        { duration: '2m', target: 0 },
    ],
    thresholds: {
        http_req_duration: ['p(95)<2000'],
        http_req_failed: ['rate<0.05'],
    },
};

export default function () {
    const url = 'http://host.docker.internal:8080/coupon/issue';

    const payload = JSON.stringify({
        userId: Math.floor(Math.random() * 100000) + 1, // 랜덤 유저 ID
        couponId: 104,
        policyId: 21,
        typeSnapshot: "FIXED",
        discountRateSnapshot: 10.0,
        discountAmountSnapshot: 1000,
        minimumOrderAmountSnapshot: 5000,
        usagePeriodSnapshot: 30,
        expiredAt: "2025-12-31T23:59:59"
    });

    const params = {
        headers: {
            'Content-Type': 'application/json',
            'Accept': 'application/json',
        },
    };

    const res = http.post(url, payload, params);

    check(res, {
        'status is 202': (r) => r.status === 202,
    });

    sleep(1); // 유저 think time
}
```

### 테스트 결과 및 개선

**동작 확인 테스트 결과**

```bash
  █ THRESHOLDS

    http_req_duration
    ✓ 'p(95)<500' p(95)=8.02ms

    http_req_failed
    ✓ 'rate<0.01' rate=0.00%

  █ TOTAL RESULTS

    checks_total.......: 1500    44.853764/s
    checks_succeeded...: 100.00% 1500 out of 1500
    checks_failed......: 0.00%   0 out of 1500

    ✓ status is 202

    HTTP
    http_req_duration..............: avg=2.55ms min=402.99µs med=1.56ms max=25.98ms p(90)=4.72ms p(95)=8.02ms
      { expected_response:true }...: avg=2.55ms min=402.99µs med=1.56ms max=25.98ms p(90)=4.72ms p(95)=8.02ms
    http_req_failed................: 0.00%  0 out of 1500
    http_reqs......................: 1500   44.853764/s

    EXECUTION
    iteration_duration.............: avg=1s     min=1s       med=1s     max=1.02s   p(90)=1s     p(95)=1s
    iterations.....................: 1500   44.853764/s
    vus............................: 50     min=50        max=50
    vus_max........................: 50     min=50        max=50

    NETWORK
    data_received..................: 272 kB 8.1 kB/s
    data_sent......................: 582 kB 17 kB/s

                                                           
```

총 1500 건의 테스트에서 p95 = 8.02ms, 실패율은 0%로 기준을 충족하였고 동작에 문제가 없음을 확인하였다.

하지만 최대 응답 시간이 25.98ms로 병목 지점이 있는 것이 의심되었다.

---

**점진적 증가 테스트 결과 및 개선**

점진적 테스트를 시작하자마자 첫 번째 문제가 발생했다.

```
The Daemon will expire after the build after running out of JVM heap space.
The project memory settings are likely not configured or are configured to an insufficient value.
The daemon will restart for the next build, which may increase subsequent build times.
These settings can be adjusted by setting 'org.gradle.jvmargs' in 'gradle.properties'.
The currently configured max heap space is '512 MiB' and the configured max metaspace is '384 MiB'.
For more information on how to set these values, please refer to https://docs.gradle.org/8.11.1/userguide/build_environment.html#sec:configuring_jvm_memory in the Gradle documentation.
To disable this warning, set 'org.gradle.daemon.performance.disable-logging=true'.
Daemon will be stopped at the end of the build after running out of JVM heap space
```

기본으로 잡혀있던 JVM 힙 메모리가 부족해 oom(Out Of Memory)이 발생하고 데몬이 죽어버렸다.

**oom 대응 및 개선**

```yaml
# JVM 메모리 설정
org.gradle.jvmargs=-Xmx4g -Dfile.encoding=UTF-8
```

gradle.properties를 생성하고 위 설정을 추가해 JVM 힙 메모리를 4GB로 설정하였다.

이 후 테스트를 진행하자 두 번째 문제가 발생하였다.

node 대시보드

![점진적 증가 node.PNG](../images/부하%20테스트%20문서%20이미지/3.png)

CPU는 안정 수준이고 memory는 점진적으로 증가하지만 아직 문제가 아니고 DB 커넥션 풀 또한 최대가 2% 정도로 병목이 아니었다.

문제는 kafka에서 발생했다.

Message in per second 는 예상대로 피크가 발생했고 메세지 발행에 문제가 없었다.

Consumer Lag에서는 순간적으로 25만건 이상의 적체가 발생했지만 극단적으로 테스트 시나리오를 설정해서 예상 내였다. 하지만 파티션이 1개로 잡혀있는 것을 확인했다.

![카프카 대시보드.PNG](../images/부하%20테스트%20문서%20이미지/1.png)

이전 구현에서 topic 설정할 때 아래처럼 파티션을 12개로 작성했다.

```java
package kr.hhplus.be.server.common.kafka;

import org.apache.kafka.clients.admin.NewTopic;
import org.springframework.context.annotation.Bean;
import org.springframework.kafka.config.TopicBuilder;

public class KafkaTopicConfig {
    @Bean
    public NewTopic paymentTopic() {
        return TopicBuilder.name("payment-completed")
            .partitions(12)
            .replicas(3)
            .build();
    }

    @Bean
    public NewTopic couponIssueTopic() {
        return TopicBuilder.name("coupon-issue")
                .partitions(12)
                .replicas(3)
                .build();
    }
}
```

```bash
docker exec -it kafka-1   kafka-topics --bootstrap-server kafka-1:29092   --delete --topic coupon-issue
```

명령어로 삭제 후 앱을 재기동 해 토픽을 재생성 해봐도 파티션으로 1개로 잡혔다.

원인은  
@Configuration 어노테이션이 없어서 Bean이 토픽을 생성하지 못함,
`KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"` 설정이 존재하지 않아 kafka가 자동으로 토픽을 생성.

으로 확인되어 해당 사항을 개선했다.

https://github.com/sky96027/e-commerce/commit/2b008b9634c8897c58ed23520c6333a804f6d0f8

```bash
sky96@DESKTOP-3PMC1QT:/mnt/c/Users/sky96/IdeaProjects/e-commerce$ docker exec -it kafka-1 \
  kafka-consumer-groups --bootstrap-server kafka-1:29092 \
  --describe --group coupon-issue-group

GROUP              TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                          
               HOST            CLIENT-ID
coupon-issue-group coupon-issue    2          2931            21704           18773           consumer-coupon-issue-group-15-adce7461-bd0d-41a1-a19a-4ca8a3f512a1 /172.19.0.1     consumer-coupon-issue-group-15
coupon-issue-group coupon-issue    7          3412            22338           18926           consumer-coupon-issue-group-20-30a8d85b-0664-4343-ae7a-e4acefabcc39 /172.19.0.1     consumer-coupon-issue-group-20
coupon-issue-group coupon-issue    1          3171            23385           20214           consumer-coupon-issue-group-14-0a87e631-5d60-4987-863a-610754831bdd /172.19.0.1     consumer-coupon-issue-group-14
coupon-issue-group coupon-issue    4          3335            20849           17514           consumer-coupon-issue-group-17-d765153f-00f7-4694-8d7c-4acbd620eed6 /172.19.0.1     consumer-coupon-issue-group-17
coupon-issue-group coupon-issue    3          3235            21413           18178           consumer-coupon-issue-group-16-d4e003e8-9e85-4c10-816f-2e76e855c362 /172.19.0.1     consumer-coupon-issue-group-16
coupon-issue-group coupon-issue    5          2806            24187           21381           consumer-coupon-issue-group-18-bb8a6b21-d8f0-414f-ae78-62fbdc90d609 /172.19.0.1     consumer-coupon-issue-group-18
coupon-issue-group coupon-issue    11         2897            21796           18899           consumer-coupon-issue-group-24-54595c77-8b49-4291-8a1d-df702f83d5c4 /172.19.0.1     consumer-coupon-issue-group-24
coupon-issue-group coupon-issue    8          3105            21141           18036           consumer-coupon-issue-group-21-e5a8cde3-c3f0-4b12-ad65-2cad92791bc4 /172.19.0.1     consumer-coupon-issue-group-21
coupon-issue-group coupon-issue    0          2825            22811           19986           consumer-coupon-issue-group-13-e7ea74c1-d748-4597-808b-ba202b97f1c6 /172.19.0.1     consumer-coupon-issue-group-13
coupon-issue-group coupon-issue    10         3131            23005           19874           consumer-coupon-issue-group-23-d34a4bc5-4edb-45a6-99f5-7587b1bd12ed /172.19.0.1     consumer-coupon-issue-group-23
coupon-issue-group coupon-issue    9          3088            21992           18904           consumer-coupon-issue-group-22-19df12d8-add3-4088-8c43-d9fdd58aef30 /172.19.0.1     consumer-coupon-issue-group-22
coupon-issue-group coupon-issue    6          3133            23407           20274           consumer-coupon-issue-group-19-2b99042e-8683-410b-ab7a-1b7cc93e5a12 /172.19.0.1     consumer-coupon-issue-group-19

```

파티션이 설정대로 12개로 제대로 생성됐고 컨슈머 또한 파티션 별 병렬 소비를 확인했다.

![점진적 증가.PNG](../images/부하%20테스트%20문서%20이미지/4.png)

이 후 다시 테스트 중 지표 확인 결과 DB 커넥션 풀도 파티션 대로 12개를 사용.

그리고 메세지 발행 속도(초당 1500건)에 비해 캐시와 분산 락을 모두 도입했는데도 소비 속도(초당 50건)가 마음에 들지 않아 소비 속도를 늘릴 방법을 생각했다.

1. consumer lag의 지표를 spring으로 받아와 기준을 넘지 않으면 (소규모 트래픽이면) 지금 방식대로 Loop 처리 기준을 넘으면 (대규모 트래픽이면) 쿼리를 bulk로 날려서 처리.
    1. 이 경우 너무 위험하다고 판단해 포기했다.
    2. 99명이 성공하고 1명이 실패할 경우 모두 실패하게 되고 보상 로직도 복잡해지며 정합성에 문제가 생길 것 같아 포기했다.
2. 캐시의 확장
    1. 현재 구조는 Redis에서 감소 → DB로 write-through
    2. 이 구조를 DB는 일정 주기로 Sync하고 실시간 정합성은 Redis에서만 보장하게 변경한다면 성능이 극대화되겠지만
    3. Redis가 장애가 생길 경우와 최종 정합성에 문제가 생길 것 같아 보류.
3. DB 샤딩
    1. “물리적” 샤딩
        1. 이 경우 트래픽이 여러 DB로 분산되므로 처리량이 증가한다.
        2. 하지만 운영 복잡도가 증가한다.(샤딩 키 관리, 운영 비용 증가)
    2. “논리적” 샤딩
        1. coupon_issue 테이블을 coupon_id + shard_no으로 나눈다.
        2. 하드웨어 증설이 필요하지 않아 비용이 거의 들지 않으며 운영 부담이 낮다.

대규모의 트래픽을 받는 가상 시나리오에서 지금 내가 선택할 수 있는 것은 논리적 샤딩이라고 생각한다.

**러프하게 스케치만한 설계**

```sql
CREATE TABLE coupon_issue_shard (
    coupon_issue_id BIGINT AUTO_INCREMENT PRIMARY KEY,
    coupon_id BIGINT NOT NULL,
    shard_no INT NOT NULL,
    remaining INT NOT NULL,
    UNIQUE(coupon_id, shard_no)
);
```

예: 쿠폰 `coupon_id = 104`, 발급량 10,000장

- shard_no = 0, remaining = 2,500
- shard_no = 1, remaining = 2,500
- shard_no = 2, remaining = 2,500
- shard_no = 3, remaining = 2,500

```java
int shardNo = ThreadLocalRandom.current().nextInt(0, shardCount);
int rows = jdbcTemplate.update("""
    UPDATE coupon_issue_shard
       SET remaining = remaining - 1
     WHERE coupon_id = ?
       AND shard_no = ?
       AND remaining > 0
""", couponId, shardNo);
```

coupon_id + 랜덤한 샤드no 선택 해서 차감.

이렇게 리팩토링할 경우 락이 더욱 분산되어 동시성 처리량이 증가할 것이라 예상하며 운영 비용도 증가하지 않고 도입 난이도도 비교적 낮을 것이라 예상한다.