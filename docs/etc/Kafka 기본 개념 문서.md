## Topic

- 정의 : 관련 이벤트들의 논리적 묶음, 애플리케이션은 토픽 이름으로 쓰고 읽음.
  데이터를 구분하기 위한 저장소.

![Kafka Topic](../images/Kafka%20기본%20개념%20문서%20이미지/1.png)

- 특징
    - 순서 개념이 없으며 순서는 파티션 단위에서 보장됨.
    - 같은 비즈니스 도메인이라도 읽기 패턴이나 보관 정책이 다르면 토픽을 분리함 (예: `orders`, `order-status`, `order-dlq` 등)
    - 설정 예
        - `num.partitions`: 파티션 개수(병렬성·처리량의 1차 결정 요소)
        - `cleanup.policy`: 보관 방식(`delete` / `compact` / `compact,delete`)
    - 용도 : producer, consumer 간 결합도를 낮추면서(이름만 공유) 필요한 보관, 성능 특성을 스트림 단위로 분리

## Partition

- 정의 : 토픽을 물리적으로 쪼갠 조각. 각 파티션은 append-only로 로그 파일들의 연속이며 그 파티션 안에서만 레코드 순서가 유지된다.

![Kafka Partition](../images/Kafka%20기본%20개념%20문서%20이미지/2.png)

- 특징
    - 병렬성 : consumer 그룹은 파티션을 나눠 읽으므로 파티션 수가 곧 동시 처리 폭이 됨.
    - 확장성 : 파티션을 늘려 처리량을 키울 수 있다.
    - 순서 제어 : 같은 키는 같은 파티션 규칙으로 키 단위의 순서를 지킬 수 있다.
    - 키 → 파티션 매핑
        - 키가 같으면 같은 파티션으로 간다(순서 유지).
        - 키가 없으면(null key) 프로듀서는 sticky/round-robin으로 고르게 분산한다(키 단위 순서 보장은 없다).
- 주의 사항
    - 파티션 수를 나중에 늘리면 `hash(key) % n`의 n이 바뀌어 같은 키가 다른 파티션으로 이동할 수 있다. 그 결과, 토픽의 과거에 있던 같은 키의 기록과 미래의 기록이 서로 다른 파티션에 존재할 수 있고, 키 전역 순서를 시간 축 전체로 강하게 요구하는 경우엔 문제가 된다.
        - 해결책: 초기에 여유 분의 파티션을 잡거나, 커스텀 파티셔너(예: 일관 해싱 + 버킷 테이블)로 키→버킷→파티션 2단계 매핑을 도입해 재배치 비용을 줄인다.
    - 파티션을 너무 많이 두면 파일·FD·메모리·리밸런스 부담이 커진다. 반대로 너무 적으면 컨슈머 확장이 막힌다. 초기 용량 계획이 중요하다.

## Leader, Follower, ISR

- Leader/Follower: 파티션은 1개의 리더와 여러 팔로워(replica)로 구성. 쓰기와 읽기는 리더가 담당.
- ISR(In-Sync Replicas): 리더를 충분히 따라잡은 복제본들의 집합.
    - 리더의 HW(High Watermark)는 ISR 모두가 가진 마지막 오프셋까지 전진한다. 컨슈머는 이 경계까지만 읽는다(안전한 읽기).
- 복제 흐름
    1. 프로듀서가 리더에 append
    2. 팔로워들이 리더에서 fetch → 로컬 로그에 기록
    3. ISR 모두 기록 완료 시 HW 전진(커밋 경계 이동)
- 내구성 조합
    - `acks=all` + 토픽/브로커의 `min.insync.replicas = M` → 리더 + (M-1) 팔로워까지 기록되어야 성공 응답.
    - 네트워크 분할·개별 장애에도 **데이터 손실 가능성 최소화.**
- 용도 : 가용성(리더 장애 시 교체)과 일관성(HW 경계)을 동시에 달성하는 구조.

## Broker

- 정의 : producer/consumer의 요청을 받아 파티션 로그를 디스크에 append하고 복제,조회,보관을 담당하는 서버 프로세스

![Kafka Broker](../images/Kafka%20기본%20개념%20문서%20이미지/3.png)

- 내부 구성
    - 네트워크 레이어 : 요청/응답을 처리하는 I/O 스레드와 큐.
    - 로그 서브시스템 : 파티션 별 세그먼트, 오프셋 인덱스, 타임 인덱스 관리, 활성 세그먼트에만 append.
    - 복제(fetcher) 스레드 : 팔로워가 리더로부터 새 레코드를 당겨와 자기 로그에 동일하게 기록.
    - log cleaner : `compact` 토픽에서 키당 최신 값만 남기도록 백그라운드 압축.
    - 페이지 캐시 활용 : OS 페이지 캐시를 적극 활용(쓰기/읽기 대역폭 최적화)
- 용도 : 고속 append, 순차 디스크 접근을 전제로 지속성, 처리량을 확보하는 실행 단위.

## Controller(KRaft)

- 기존의 Zookeeper를 대체하며 브로커들 중 일부가 컨트롤러 역할을 맡아 Raft 합의로 클러스터 메타데이터 로그를 관리.
- 역할
    - 브로커 등록, 세션 관리 : 노드가 합류/이탈할 때 메타데이터 갱신.
    - 토픽/파티션 메타데이터 : 생성, 삭제, 파티션 변경, 리더 할당.
    - 리더 선출 : 리더 브로커가 죽거나 느려지면 ISR 중 하나를 새 리더로 승격.
    - 파티션 재할당 : 특정 브로커에 쏠린 파티션을 다른 브로커로 이동.
    - 선호 리더(Preferred Leader) 복구 : 계획해 둔 리더로 되돌림.
- 구성 모드
    - Controller-only 노드 : 컨트롤러 전용.
    - Broker+Contoller 겸임 : 소규모환경에서 단순화.
- 용도 : 클러스터의 Single Source of Truth로서 안정적 리더 선출/할당, 스케일, 장애 복구를 조정.

## Producer

![Kafka Producer](../images/Kafka%20기본%20개념%20문서%20이미지/4.png)

### Producer가 보내는 단위 : Record

- Record : `(key, value, headers, timestamp)`
- Batch : 같은 파티션으로 향하는 레코드들을 모아 한 번에 전송(네트워크 왕복, 시스템 콜 감소)
    - **`linger.ms`**: 조금 더 기다렸다가 모아서 보낼지 대기 시간(기본 0이면 도착 즉시 배치 종료).
    - **`batch.size`**(bytes): 배치 최대 크기. 가득 차거나 `linger.ms` 만료 시 전송.
    - 압축**(`compression.type`)**: `none/gzip/snappy/lz4/zstd` — 전송량↓(디스크·네트워크 절감) ↔ CPU↑.

### Partition 까지의 전송 과정

- Serializer : 지정된 설정을 통해 처리, 메시지의 키와 값은 바이트 뭉치 형태로 변환.
- Partitioner : 토픽의 어떤 파티션에 저장할지 결정.
    - 정의된 로직에 따라 파티셔닝을 진행.
    - 정의되지 않았으면 Round Robbin 형태로 파티셔닝
- Compression : 설정된 포맷에 맞춰 메세지를 압축.
    - 압축은 옵션이지만 압축된 메세지는 브로커로 빠르게 전달할 수 있으며 브로커 내부에서 빠른 복제가 가능.

  ![Kafka Compression](../images/Kafka%20기본%20개념%20문서%20이미지/5.png)


### acks

- `acks=all(-1)`: 리더 + `min.insync.replicas` 개수만큼 복제 성공해야 성공 응답. 권장 기본값(내구성 최우선).
- `acks=1`: 리더만 기록하면 성공(팔로워 복제 전 장애 시 유실 위험).
- `acks=0`: 응답 안 기다림(최저 지연, 최고 위험).
- 연계 파라미터: 토픽/브로커의 `min.insync.replicas`(예: 2)와 함께 내구성 기준을 완성.
- 용도: 내구성↔지연 정책의 1차 스위치.

## Consumer

컨슈머 API와 그것으로 구성된 애플리케이션. 토픽 파티션에 저장된 메세지들을 가져와 처리한다.

### Consumer의 세 가지 특징

- Polling 구조
    - 다른 메세징 큐는 메세지 큐에서 메세지를 Push한다. 이 방식의 가장 큰 단점은 메세지 큐가 컨슈머 측의 처리 성능을 염두해야 한다.
    - 하지만 Kafka는 컨슈머가 브로커로부터 메세지를 Polling 한다. 즉, 컨슈머는 자신이 원하는 만큼의 메세지를 브로커에게 요청한다.
- 단일 토픽의 멀티 컨슈밍

  ![Kafka multi consume](../images/Kafka%20기본%20개념%20문서%20이미지/6.png)

    - 하나의 토픽에 서로 다른 컨슈머 애플리케이션이 동시에 구독할 수 있다.
    - 이것이 가능한 이유는 컨슈머가 메세지를 읽을 때 브로커의 메세지가 삭제되는 것이 아니기 때문이다. 대신에 각 컨슈머가 어느 토픽 파티션의 어느 오프셋까지 읽어갔는 지 컨슈머 오프셋 이라는 토픽에 저장한다.
- 컨슈머 그룹

  ![Kafka Consumer Group](../images/Kafka%20기본%20개념%20문서%20이미지/7.png)

    - 둘 이상의 파티션을 하나의 컨슈머로만 처리하면 성능 상의 문제가 발생할 수 있다. 그래서 둘 이상의 컨슈머로 그룹을 구성하여 하나의 토픽을 구독해 처리량을 증가시킬 수 있다.
    - 컨슈머 그룹 내의 컨슈머는 파티션의 소유권을 나눠 갖는다.
    - 컨슈머 그룹에 컨슈머가 추가되거나 이탈한다면 그룹 내부에서 소유권이 재조정되며 이를 리밸런싱(Rebalancing) 이라고 한다.